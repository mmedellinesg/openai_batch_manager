{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required packages\n",
    "\n",
    "For this example, aside from the `openai_batch_manager` repository, I will be using `configparser` to feed in an OpenAI API key without hard-coding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai_batch_manager.batch_manager import BatchManager\n",
    "from openai_batch_manager.jsonl_filewriter import write_jsonl_file_from_df\n",
    "import configparser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OpenAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../../config.ini')\n",
    "openai_key = config['API_KEYS']['openai']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample dataframe\n",
    "\n",
    "Suppose our task is to take [Yelp reviews](https://huggingface.co/datasets/Yelp/yelp_review_full) of doctors and use ChatGPT to help us rate their bedside manner. Our sample dataframe contains some Yelp reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"dr. goldberg offers everything i look for in a general practitioner. he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first. really, what more do you need? i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\",\n",
    "        \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff. It seems that his staff simply never answers the phone. It usually takes 2 hours of repeated calling to get an answer. Who has time for that or wants to deal with it? I have run into this problem with many other doctors and I just don't get it. You have office workers, you have patients with medical needs, why isn't anyone answering the phone? It's incomprehensible and not work the aggravation. It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\",\n",
    "        \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\",\n",
    "        \"Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June. He will be missed very much. \\n\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!\",\n",
    "        \"I don't know what Dr. Goldberg was like before moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `jsonl_filewriter`: Module to create batch files from dataframes\n",
    "\n",
    "## Prompt\n",
    "\n",
    "Let's say that we want to apply the same instructions to all comments. In this example, I set the prompt in `system`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "You are a specialist in patient-focused healthcare in charge of rating a doctor's bedside manner using Yelp comments.\n",
    "For every entry, you will rate the doctor's bedside manner in a scale from 1-5, where 1 is the worst and 5 is the best.\n",
    "If the comment contains no relevant information, please give a rating of 0.\n",
    "\n",
    "Respond in JSON format:\n",
    "{\n",
    "    'bedside_rating':<0-5>,\n",
    "    'explanation':<20 or less word-long fragment of the comment that justifies your choice, 'none' if irrelevant>\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing input batch file\n",
    "\n",
    "The OpenAI batch API takes `jsonl` files as inputs. The function `write_jsonl_file_from_df` allows us to convert a dataframe column into one such file in a single step. We only need to input `df`, the `system` prompt, the `df` column from which we will create `user` messages (in our case, `text`), and the model. We can also set other features, such as `max_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_content = write_jsonl_file_from_df(\n",
    "    df, system, 'text', model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is a string that is ready to be written to a `jsonl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"\\nYou are a specialist in patient-focused healthcare in charge of rating a doctor's bedside manner using Yelp comments.\\nFor every entry, you will rate the doctor's bedside manner in a scale from 1-5, where 1 is the worst and 5 is the best.\\nIf the comment contains no relevant information, please give a rating of 0.\\n\\nRespond in JSON format:\\n{\\n    'bedside_rating':<0-5>,\\n    'explanation':<20 or less word-long fragment of the comment that justifies your choice, 'none' if irrelevant>\\n}\\n\"}, {\"role\": \"user\", \"content\": \"dr. goldberg offers everything i look for in a general practitioner. he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first. really, what more do you need? i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"}], \"max_tokens\": 4096}}\n",
      "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"\\nYou are a specialist in patient-focused healthcare in charge of rating a doctor's bedside manner using Yelp comments.\\nFor every entry, you will rate the doctor's bedside manner in a scale from 1-5, where 1 is the worst and 5 is the best.\\nIf the comment contains no relevant information, please give a rating of 0.\\n\\nRespond in JSON format:\\n{\\n    'bedside_rating':<0-5>,\\n    'explanation':<20 or less word-long fragment of the comment that justifies your choice, 'none' if irrelevant>\\n}\\n\"}, {\"role\": \"user\", \"content\": \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff. It seems that his staff simply never answers the phone. It usually takes 2 hours of repeated calling to get an answer. Who has time for that or wants to deal with it? I have run into this problem with many other doctors and I just don't get it. You have office workers, you have patients with medical needs, why isn't anyone answering the phone? It's incomprehensible and not work the aggravation. It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\"}], \"max_tokens\": 4096}}\n",
      "{\"custom_id\": \"request-3\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"\\nYou are a specialist in patient-focused healthcare in charge of rating a doctor's bedside manner using Yelp comments.\\nFor every entry, you will rate the doctor's bedside manner in a scale from 1-5, where 1 is the worst and 5 is the best.\\nIf the comment contains no relevant information, please give a rating of 0.\\n\\nRespond in JSON format:\\n{\\n    'bedside_rating':<0-5>,\\n    'explanation':<20 or less word-long fragment of the comment that justifies your choice, 'none' if irrelevant>\\n}\\n\"}, {\"role\": \"user\", \"content\": \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\"}], \"max_tokens\": 4096}}\n",
      "{\"custom_id\": \"request-4\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"\\nYou are a specialist in patient-focused healthcare in charge of rating a doctor's bedside manner using Yelp comments.\\nFor every entry, you will rate the doctor's bedside manner in a scale from 1-5, where 1 is the worst and 5 is the best.\\nIf the comment contains no relevant information, please give a rating of 0.\\n\\nRespond in JSON format:\\n{\\n    'bedside_rating':<0-5>,\\n    'explanation':<20 or less word-long fragment of the comment that justifies your choice, 'none' if irrelevant>\\n}\\n\"}, {\"role\": \"user\", \"content\": \"Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June. He will be missed very much. \\n\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!\"}], \"max_tokens\": 4096}}\n",
      "{\"custom_id\": \"request-5\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"\\nYou are a specialist in patient-focused healthcare in charge of rating a doctor's bedside manner using Yelp comments.\\nFor every entry, you will rate the doctor's bedside manner in a scale from 1-5, where 1 is the worst and 5 is the best.\\nIf the comment contains no relevant information, please give a rating of 0.\\n\\nRespond in JSON format:\\n{\\n    'bedside_rating':<0-5>,\\n    'explanation':<20 or less word-long fragment of the comment that justifies your choice, 'none' if irrelevant>\\n}\\n\"}, {\"role\": \"user\", \"content\": \"I don't know what Dr. Goldberg was like before moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\"}], \"max_tokens\": 4096}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jsonl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then write it to a jsonl file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('infile.jsonl','w') as f:\n",
    "    f.write(jsonl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `BatchManager`: Class to upload files, check status and download outputs\n",
    "\n",
    "We initialize the `BatchManager` class with the OpenAI API key and a path to a `csv` file where the GPT inputs and outputs will be logged (this file is created if it does not yet exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = BatchManager(\n",
    "    api_key=openai_key,\n",
    "    log_path='log.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting batch files\n",
    "\n",
    "Once initialized, we can use the `BatchManager` class to upload our newly created input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged submission: batch_682cf07d93408190a26fecf77b109a4b\n",
      "Uploaded file: file-5GCTwc4cDMcMoAxUM9wgoA\n",
      "Submitted batch: batch_682cf07d93408190a26fecf77b109a4b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('file-5GCTwc4cDMcMoAxUM9wgoA', 'batch_682cf07d93408190a26fecf77b109a4b')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.submit_batch(\n",
    "    'infile.jsonl',\n",
    "    purpose='Rate bedside manner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log file is automatically updated with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submission_datetime</th>\n",
       "      <th>purpose</th>\n",
       "      <th>infile</th>\n",
       "      <th>infile_id</th>\n",
       "      <th>status</th>\n",
       "      <th>status_datetime</th>\n",
       "      <th>outfile</th>\n",
       "      <th>outfile_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_682cf07d93408190a26fecf77b109a4b</td>\n",
       "      <td>2025-05-20T17:13:33.859758</td>\n",
       "      <td>Rate bedside manner</td>\n",
       "      <td>infile.jsonl</td>\n",
       "      <td>file-5GCTwc4cDMcMoAxUM9wgoA</td>\n",
       "      <td>created</td>\n",
       "      <td>2025-05-20T17:13:33.859758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id         submission_datetime  \\\n",
       "0  batch_682cf07d93408190a26fecf77b109a4b  2025-05-20T17:13:33.859758   \n",
       "\n",
       "               purpose        infile                    infile_id   status  \\\n",
       "0  Rate bedside manner  infile.jsonl  file-5GCTwc4cDMcMoAxUM9wgoA  created   \n",
       "\n",
       "              status_datetime  outfile  outfile_id  \n",
       "0  2025-05-20T17:13:33.859758      NaN         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.logger.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoiding duplicate uploads\n",
    "\n",
    "The `submit_batch` function allows the user to specify if they want to skip files they have previously uploaded, according to the log file. By default, this feature is set to `True`. If set to `False`, the user will get a warning, but the upload will proceed.\n",
    "\n",
    "If we try to re-upload `infile.jsonl`, this is the output we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/home/mmedelli/prosociality-reddit-crime/build_functions/submodules/openai_batch_manager/batch_manager.py:24: UserWarning: File infile.jsonl has already been submitted with batch ID batch_682cf07d93408190a26fecf77b109a4b and status created.\n",
      "  warnings.warn(f\"File {this_file} has already been submitted with batch ID {batch_id} and status {batch_status}.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File 'infile.jsonl' has already been submitted — aborting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/users/mmedelli/prosociality-reddit-crime/build_functions/submodules/example.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/mmedelli/prosociality-reddit-crime/build_functions/submodules/example.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m manager\u001b[39m.\u001b[39;49msubmit_batch(\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/mmedelli/prosociality-reddit-crime/build_functions/submodules/example.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39minfile.jsonl\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/mmedelli/prosociality-reddit-crime/build_functions/submodules/example.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     purpose\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRate bedside manner\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/mmedelli/prosociality-reddit-crime/build_functions/submodules/example.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     duplicate_skip\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.ccv.brown.edu/users/mmedelli/prosociality-reddit-crime/build_functions/submodules/example.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[0;32m/oscar/home/mmedelli/prosociality-reddit-crime/build_functions/submodules/openai_batch_manager/batch_manager.py:27\u001b[0m, in \u001b[0;36mBatchManager.submit_batch\u001b[0;34m(self, infile, purpose, duplicate_skip)\u001b[0m\n\u001b[1;32m     24\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mthis_file\u001b[39m}\u001b[39;00m\u001b[39m has already been submitted with batch ID \u001b[39m\u001b[39m{\u001b[39;00mbatch_id\u001b[39m}\u001b[39;00m\u001b[39m and status \u001b[39m\u001b[39m{\u001b[39;00mbatch_status\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m         \u001b[39mif\u001b[39;00m duplicate_skip:\n\u001b[0;32m---> 27\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mthis_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has already been submitted — aborting.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m uploaded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mupload_file(infile)\n\u001b[1;32m     30\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate_batch(uploaded\u001b[39m.\u001b[39mid, purpose)\n",
      "\u001b[0;31mValueError\u001b[0m: File 'infile.jsonl' has already been submitted — aborting."
     ]
    }
   ],
   "source": [
    "manager.submit_batch(\n",
    "    'infile.jsonl',\n",
    "    purpose='Rate bedside manner',\n",
    "    duplicate_skip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking on batch status\n",
    "\n",
    "Through `BatchManager`, the user can easily check the progress of their batches. The only required input is the `batch_id` that identifies the relevant task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: batch_682cf07d93408190a26fecf77b109a4b\n",
      "Submitted: 2025-05-20 17:13:33\n",
      "Status: completed\n",
      "Updated status for batch: batch_682cf07d93408190a26fecf77b109a4b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_682cf07d93408190a26fecf77b109a4b', completion_window='24h', created_at=1747775613, endpoint='/v1/chat/completions', input_file_id='file-5GCTwc4cDMcMoAxUM9wgoA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747785874, error_file_id=None, errors=None, expired_at=None, expires_at=1747862013, failed_at=None, finalizing_at=1747785873, in_progress_at=1747775618, metadata={'description': 'Rate bedside manner'}, output_file_id='file-CUz44cMqQ1hT1GZZTCknHi', request_counts=BatchRequestCounts(completed=5, failed=0, total=5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.check_status(manager.logger.df.iloc[0]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This updates the `log` file by default, but is a feature that can be turned off (by setting `update_log=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submission_datetime</th>\n",
       "      <th>purpose</th>\n",
       "      <th>infile</th>\n",
       "      <th>infile_id</th>\n",
       "      <th>status</th>\n",
       "      <th>status_datetime</th>\n",
       "      <th>outfile</th>\n",
       "      <th>outfile_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_682cf07d93408190a26fecf77b109a4b</td>\n",
       "      <td>2025-05-20T17:13:33.859758</td>\n",
       "      <td>Rate bedside manner</td>\n",
       "      <td>infile.jsonl</td>\n",
       "      <td>file-5GCTwc4cDMcMoAxUM9wgoA</td>\n",
       "      <td>completed</td>\n",
       "      <td>2025-05-21T08:56:49.755675</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id         submission_datetime  \\\n",
       "0  batch_682cf07d93408190a26fecf77b109a4b  2025-05-20T17:13:33.859758   \n",
       "\n",
       "               purpose        infile                    infile_id     status  \\\n",
       "0  Rate bedside manner  infile.jsonl  file-5GCTwc4cDMcMoAxUM9wgoA  completed   \n",
       "\n",
       "              status_datetime outfile outfile_id  \n",
       "0  2025-05-21T08:56:49.755675     nan        nan  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.logger.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading files\n",
    "\n",
    "Once the download has been completed, `BatchManager` can be used to download the output files and log their ID and path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated status for batch: batch_682cf07d93408190a26fecf77b109a4b\n",
      "Updated outfile for batch: batch_682cf07d93408190a26fecf77b109a4b\n",
      "Downloaded results for batch: batch_682cf07d93408190a26fecf77b109a4b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.download_if_ready(\n",
    "    batch_id=manager.logger.df.iloc[0]['id'],\n",
    "    out_path='outfile.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submission_datetime</th>\n",
       "      <th>purpose</th>\n",
       "      <th>infile</th>\n",
       "      <th>infile_id</th>\n",
       "      <th>status</th>\n",
       "      <th>status_datetime</th>\n",
       "      <th>outfile</th>\n",
       "      <th>outfile_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_682cf07d93408190a26fecf77b109a4b</td>\n",
       "      <td>2025-05-20T17:13:33.859758</td>\n",
       "      <td>Rate bedside manner</td>\n",
       "      <td>infile.jsonl</td>\n",
       "      <td>file-5GCTwc4cDMcMoAxUM9wgoA</td>\n",
       "      <td>completed</td>\n",
       "      <td>2025-05-21T08:56:55.126287</td>\n",
       "      <td>outfile.json</td>\n",
       "      <td>file-CUz44cMqQ1hT1GZZTCknHi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id         submission_datetime  \\\n",
       "0  batch_682cf07d93408190a26fecf77b109a4b  2025-05-20T17:13:33.859758   \n",
       "\n",
       "               purpose        infile                    infile_id     status  \\\n",
       "0  Rate bedside manner  infile.jsonl  file-5GCTwc4cDMcMoAxUM9wgoA  completed   \n",
       "\n",
       "              status_datetime       outfile                   outfile_id  \n",
       "0  2025-05-21T08:56:55.126287  outfile.json  file-CUz44cMqQ1hT1GZZTCknHi  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.logger.df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
